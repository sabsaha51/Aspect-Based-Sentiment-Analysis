{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCJAkNSDH6MI",
    "outputId": "b6a60b04-15d1-4afe-99ce-00f247cbed23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neuralcoref\n",
      "  Downloading https://files.pythonhosted.org/packages/51/30/513e85d805a6d652868f74ce5579a00490491944745c705067a041bef8f1/neuralcoref-4.0-cp37-cp37m-win_amd64.whl (227kB)\n",
      "Requirement already satisfied: spacy>=2.1.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from neuralcoref) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from neuralcoref) (1.18.4)\n",
      "Collecting boto3 (from neuralcoref)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/77/cc19511d0fe4672890209ebcbfb9b3f4746572f5a48f7ed2654e7f8c2f29/boto3-1.17.89-py2.py3-none-any.whl (131kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from neuralcoref) (2.25.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (3.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (4.60.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (57.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (0.4.1)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->neuralcoref)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.5.0,>=0.4.0 (from boto3->neuralcoref)\n",
      "  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
      "Collecting botocore<1.21.0,>=1.20.89 (from boto3->neuralcoref)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/20/e6e16f588036b387d4f4f8e2e780a520e2b3925ba1529fdfc97ad909fb6c/botocore-1.20.89-py2.py3-none-any.whl (7.6MB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2020.12.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from botocore<1.21.0,>=1.20.89->boto3->neuralcoref) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.89->boto3->neuralcoref) (1.12.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\sabby\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (7.2.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, neuralcoref\n",
      "Successfully installed boto3-1.17.89 botocore-1.20.89 jmespath-0.10.0 neuralcoref-4.0 s3transfer-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uB3pABxJo92",
    "outputId": "5b75b723-83ce-497e-96ec-50da809b94f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-multilearn\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
      "Installing collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VnR-5qIkOte",
    "outputId": "1e32e697-fdd6-4c63-c84a-21082f138b3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sabby\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Sabby\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 112 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Sabby\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "100%|██████████████████████████████████████████████████████████████████| 40155833/40155833 [00:12<00:00, 3252520.08B/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import neuralcoref\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYFOYoCGlkma",
    "outputId": "36b2a60e-d1c3-4f2b-b1d8-5be8edb66292"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sabby\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sabby\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Uncomment this\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TlVH5rnxs0s6"
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('C:/Users/Sabby/Downloads/NLP Assignment 3/Restaurants_Train.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1098U3SCs800"
   },
   "source": [
    "Parsing Xml File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZXD0OvDs7UL",
    "outputId": "614c0568-a572-44f3-9ec1-de6d97255c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3041 reviews in this training set\n"
     ]
    }
   ],
   "source": [
    "labeled_reviews = []\n",
    "\n",
    "for sentence in root.findall(\"sentence\"):\n",
    "    entry = {}\n",
    "    aterms = []\n",
    "    aspects = []\n",
    "    if sentence.find(\"aspectTerms\"):\n",
    "        for aterm in sentence.find(\"aspectTerms\").findall(\"aspectTerm\"):\n",
    "            aterms.append(aterm.get(\"term\"))\n",
    "    if sentence.find(\"aspectCategories\"):\n",
    "        for aspect in sentence.find(\"aspectCategories\").findall(\"aspectCategory\"):\n",
    "            aspects.append(aspect.get(\"category\"))\n",
    "    entry[\"text\"], entry[\"terms\"], entry[\"aspects\"]= sentence[0].text, aterms, aspects\n",
    "    labeled_reviews.append(entry)\n",
    "\n",
    "labeled_df = pd.DataFrame(labeled_reviews)\n",
    "\n",
    "\n",
    "print(f'There are {len(labeled_reviews)} reviews in this training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VVWa8qRntBY_",
    "outputId": "bceb1703-4c88-4288-eb9f-a29d62000f77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  terms  \\\n",
       "0               But the staff was so horrible to us.                [staff]   \n",
       "1  To be completely fair, the only redeeming fact...                 [food]   \n",
       "2  The food is uniformly exceptional, with a very...  [food, kitchen, menu]   \n",
       "3  Where Gabriela personaly greets you and recomm...                     []   \n",
       "4  For those that go once and don't enjoy it, all...                     []   \n",
       "\n",
       "                           aspects  \n",
       "0                        [service]  \n",
       "1  [food, anecdotes/miscellaneous]  \n",
       "2                           [food]  \n",
       "3                        [service]  \n",
       "4        [anecdotes/miscellaneous]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save annotated reviews\n",
    "\n",
    "labeled_df.to_pickle(\"C:/Users/Sabby/Downloads/NLP Assignment 3/annotated_reviews_df.pkl\")\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en\n",
      "  Downloading https://files.pythonhosted.org/packages/21/75/1ade7951baf8b99dc322714ab9dd80054d3cb9f668c27a778bf373d1c631/en-0.0.1.tar.gz\n",
      "Building wheels for collected packages: en\n",
      "  Building wheel for en (setup.py): started\n",
      "  Building wheel for en (setup.py): finished with status 'done'\n",
      "  Created wheel for en: filename=en-0.0.1-cp37-none-any.whl size=1156 sha256=2276b37920db48ab847950e0a3124754050f3de4f6b838ed8d2219359fb757d7\n",
      "  Stored in directory: C:\\Users\\Sabby\\AppData\\Local\\pip\\Cache\\wheels\\00\\43\\90\\056879336c6fad1a3c6b467a91f507232904a939224871653c\n",
      "Successfully built en\n",
      "Installing collected packages: en\n",
      "Successfully installed en-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LOdZAjk6tEzK"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c2ed1c383b75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mneuralcoref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Define function for replacing pronouns using neuralcoref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "# Define function for replacing pronouns using neuralcoref\n",
    "def replace_pronouns(text):\n",
    "    doc = nlp(text)\n",
    "    return doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "qU9le8C2thrz",
    "outputId": "a2d64123-c5a5-4ce7-b368-140f671f4e8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...                          aspects\n",
       "0               But the staff was so horrible to us.  ...                        [service]\n",
       "1  To be completely fair, the only redeeming fact...  ...  [food, anecdotes/miscellaneous]\n",
       "2  The food is uniformly exceptional, with a very...  ...                           [food]\n",
       "3  Where Gabriela personaly greets you and recomm...  ...                        [service]\n",
       "4  For those that go once and don't enjoy it, all...  ...        [anecdotes/miscellaneous]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read annotated reviews DataFrame\n",
    "\n",
    "annotated_reviews_df = pd.read_pickle(\"/content/sample_data/annotated_reviews_df.pkl\")\n",
    "annotated_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lB2IPuOyto5M"
   },
   "outputs": [],
   "source": [
    "# Create a new column with fixed co-referencing\n",
    "\n",
    "annotated_reviews_df[\"fixed_review\"] = annotated_reviews_df[\"text\"].map(lambda x: replace_pronouns(x))\n",
    "\n",
    "annotated_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k_VFWU3ts3q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ABSA-6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
